# 프로젝트 진행 현황

> 재활용 선별장 AI 분류 시스템 - 기술 개발 및 배포 계획

마지막 업데이트: 2025년 10월 12일

---

## 목차

1. [프로젝트 개요](#프로젝트-개요)
2. [지금까지 해결한 주요 과제](#지금까지-해결한-주요-과제)
   - 디스플레이-카메라 동기화 문제
   - Jetson 플랫폼의 제약 극복
   - 카메라 연결 및 제어
   - YOLO 모델 통합 및 최적화
   - 입력 소스 확장
   - 개발 환경 정리
3. [현재 시스템 구성](#현재-시스템-구성)
4. [앞으로 해야 할 작업](#앞으로-해야-할-작업)
   - 1단계: 현장 배포 준비
   - 2단계: 원격 관리 시스템 구축
   - 3단계: AI 모델 성능 향상
   - 4단계: MLOps 파이프라인 구축
   - 5단계: 하드웨어 업그레이드 검토
5. [예산 및 리소스 계획](#예산-및-리소스-계획)
6. [기술적 과제 및 리스크](#기술적-과제-및-리스크)
7. [성공 지표](#성공-지표)
8. [마일스톤](#마일스톤)
9. [결론](#결론)

---

## 프로젝트 개요

재활용 선별장의 컨베이어 벨트 위를 카메라로 촬영하여 재활용품을 인식하고, 프로젝터를 통해 작업자들이 분류하는데 도움이 되도록 표시하는 시스템을 개발하고 있습니다. 컨베이어 벨트에서 약 3m x 1m 범위의 영역을 촬영하며, 프로젝터 프레임을 짝수/홀수로 구분하여 동기화합니다. 짝수 프레임에는 검은 화면을 내보내 카메라 촬영 시 프로젝터 빛의 영향을 최소화하고, 홀수 프레임에는 AI 인식 결과를 표시합니다.

하드웨어는 글로벌 셔터 카메라, Jetson Nano Super (Orin Nano), 옵토마 레이저 DLP 프로젝터를 사용합니다. 소프트웨어는 Ubuntu 기반으로 동작하며, 디스플레이의 VSync 신호에 맞춰 카메라 셔터를 동기화하여 촬영하고, YOLO 모델로 객체를 인식합니다.

---

## 지금까지 해결한 주요 과제

### 디스플레이-카메라 동기화 문제

프로젝터와 카메라를 정밀하게 동기화하는 것이 이 프로젝트의 핵심 기술적 과제였습니다. 초기에는 일반적인 타이머 기반 접근을 시도했지만, 프레임 드랍이 빈번하게 발생했고, 프로젝터가 표시하는 프레임과 카메라가 촬영하는 프레임이 어긋나는 문제가 있었습니다.

이를 해결하기 위해 디스플레이의 수직 동기화 신호(VSync)를 활용하는 방법을 연구했습니다. 프로젝터나 카메라에서 직접 동기화 신호를 제공하는 방법도 있지만, Genlock을 지원하는 프로젝터는 매우 고가이고, 3D Sync를 지원하는 제품도 제한적입니다. 결국 소프트웨어 레벨에서 디스플레이의 VSync 신호를 추출하여 활용하는 방향으로 결정했습니다.

Jetson 플랫폼에서 VSync 신호를 받는 방법을 조사한 결과, X11과 Wayland 두 가지 선택지가 있었습니다. X11에서는 GLX 확장을 통해 VSync를 추출할 수 있지만, 이중 컴포지팅 문제로 인해 프레임 타이밍이 불안정했고, C 코드를 직접 작성해야 하는 복잡함이 있었습니다. 반면 Wayland는 Presentation Protocol을 통해 정확한 프레임 타이밍 정보를 제공하고, Python으로 간단하게 구현할 수 있었습니다. 설치와 설정이 다소 번거롭지만, 구현의 단순성과 안정성을 고려하여 Wayland를 선택했습니다.

Wayland 환경에서 프레임 콜백을 받아 다음 VSync 타이밍을 예측하고, 카메라 트리거를 VSync 이전에 선행 실행하여 프레임이 준비되면 다음 VSync에 정확히 표시되도록 구현했습니다. 2프레임 주기로 검은 화면과 인식 결과를 교대로 표시하며, 60Hz 디스플레이에서 30fps의 안정적인 출력을 달성했습니다. 이 과정에서 GPU Fence를 활용한 프레임 드랍 감지 메커니즘도 구축하여, 실시간으로 프레임 스킵 여부를 모니터링할 수 있게 되었습니다.

### Jetson 플랫폼의 제약 극복

Jetson은 ARM64 아키텍처를 사용하는 임베디드 플랫폼으로, NVIDIA의 CUDA를 지원하지만 일반적인 x86_64 시스템과는 다른 제약사항들이 있었습니다. 가장 큰 문제는 PyTorch의 CUDA 버전이 일반 패키지 저장소에 존재하지 않아, NVIDIA가 별도로 제공하는 시스템 패키지를 활용해야 한다는 점이었습니다. 가상환경 설정을 통해 시스템에 설치된 CUDA 버전의 PyTorch를 사용할 수 있도록 환경을 구성했습니다.

Jetson의 성능을 최대한 활용하기 위해 전원 모드와 클럭 설정을 최적화하는 것도 중요했습니다. 기본 모드에서는 동적 클럭 조정으로 인해 추론 시간이 불안정했으나, 최대 성능 모드를 활성화하여 일관된 성능을 얻을 수 있었습니다. **YOLO 추론 시간이 150-200ms에서 60-112ms로 약 50-70% 개선**되었습니다.

실시간 처리 성능을 더욱 향상시키기 위해 TensorRT를 활용한 모델 최적화를 진행했습니다. TensorRT는 FP32, FP16, INT8 세 가지 정밀도 옵션을 제공하는데, 각각의 특성을 비교 분석했습니다. **PyTorch 기본 모델은 약 217ms, FP32 TensorRT는 약 112ms (2배 향상), FP16은 약 112ms (2배 향상, 메모리 50% 절약), INT8은 약 62ms (3.5배 향상)**의 성능을 보였습니다. FP16은 정확도 손실이 거의 없으면서(~99%) 속도와 메모리 효율을 동시에 개선할 수 있어 가장 균형잡힌 선택이었고, INT8은 속도가 가장 빠르지만 캘리브레이션이 필요하고 약간의 정확도 손실(~97%)이 있었습니다. 또한 FP16과 INT8을 동시에 사용할 수 없다는 제약사항도 파악하여 올바르게 구현했습니다.

### 카메라 연결 및 제어

카메라 선택에서는 글로벌 셔터와 외부 트리거 제어가 필수 요구사항이었습니다. 롤링 셔터 카메라는 빠르게 움직이는 물체를 촬영할 때 왜곡이 발생하므로, 컨베이어 벨트의 재활용품을 정확히 인식하기 위해서는 글로벌 셔터가 필요했습니다.

카메라 인터페이스로는 USB-3, GigE, MIPI/CSI 등을 고려했습니다. USB-3는 간편하지만 지연시간이 문제가 될 수 있었고, MIPI/CSI는 Jetson에 직접 연결할 수 있지만 케이블 길이 제약이 있었습니다. 최종적으로 GigE(Gigabit Ethernet) 방식을 선택했는데, 이는 산업용 표준으로 플러그앤플레이 호환성이 좋고, PoE(Power over Ethernet)를 통해 전원과 데이터를 하나의 케이블로 공급할 수 있어 설치가 간편했습니다. 다만 PoE 허브의 포트에 따라 속도 저하가 발생할 수 있어, 적절한 포트를 선택하는 것이 중요했습니다.

카메라 IP 설정도 초기에는 혼란이 있었습니다. 설정 후 즉시 확인하면 이전 IP가 표시되어, 설정이 제대로 적용되지 않았다고 오해할 수 있었습니다. 카메라는 설정 후 재시작해야 변경사항이 적용되므로, 설정 도구에 1초 대기를 추가하고 재시작 안내를 명확히 하여 해결했습니다.

### YOLO 모델 통합 및 최적화

실시간 객체 인식을 위해 YOLO 모델을 선택했습니다. 다양한 정밀도와 이미지 크기 조합을 실험할 수 있도록 GUI 기반 변환 도구를 개발했습니다. 여러 설정을 일괄 변환할 수 있는 작업 큐를 구현했고, 이미 변환된 파일은 건너뛰어 시간을 절약했습니다. 이를 통해 다양한 모델 설정을 쉽게 실험하고 최적의 조합을 찾을 수 있었습니다.

YOLOE와 같은 프롬프트 기반 모델도 지원했습니다. YOLOE는 텍스트 프롬프트로 탐지할 객체를 지정할 수 있어 유연하지만, TensorRT로 변환하면 vocabulary가 고정되어 prompt-free 모드로만 작동합니다. 이러한 차이를 UI에 명확히 표시하여, 사용자가 모델 유형에 따라 적절한 기대치를 가질 수 있도록 했습니다.

### 입력 소스 확장

현장 테스트 전에 다양한 시나리오로 알고리즘을 검증할 필요가 있어, 카메라 입력뿐만 아니라 비디오 파일 재생 기능도 구현했습니다. 사용자가 런타임에 카메라와 비디오 파일을 자유롭게 전환할 수 있도록 UI를 구성했으며, 각 입력 소스의 특성에 맞는 제어 위젯을 제공합니다. 카메라는 해상도, 노출시간, 게인 등을 실시간 조정할 수 있고, 비디오는 재생 속도를 조절할 수 있습니다. 또한 개발과 테스트를 위해 OpenGL 기반 예제나 프레임 카운터 등 다양한 UI 도구들을 함께 구현하여, 동기화 메커니즘의 정확성을 검증하고 성능을 측정할 수 있도록 했습니다.

### 개발 환경 정리

프로젝트가 커지면서 코드 구조를 정리할 필요가 있었습니다. Python과 C++ 코드를 별도 디렉토리로 분리하고, 카메라 동기화, YOLO 추론, OpenGL 예제 등 기능별로 모듈을 나눴습니다. 정밀한 타이밍 제어가 필요한 하드웨어 타이머와 Wayland Presentation 모니터링 기능은 C++로 구현하고 pybind11로 바인딩하여 Python에서 직접 사용할 수 있게 했습니다.

---

## 현재 시스템 구성

### 하드웨어 스펙

**컴퓨팅**: Jetson Orin Nano 8GB (최대 67 TOPS AI 성능, 전력 소비 10-25W). 향후 필요 시 Orin NX 16GB(157 TOPS) 또는 AGX Orin 64GB(275 TOPS)로 업그레이드 가능합니다.

**카메라**: Mindvision GigE 카메라 (2.3MP 글로벌 셔터, 최대 120fps, PoE 지원). 소프트 트리거 모드로 VSync 동기화가 가능합니다.

**프로젝터**: 옵토마 레이저 DLP 프로젝터 (5000 안시루멘, Full HD, 30,000시간 수명).

### 소프트웨어 구성

**운영체제**: Ubuntu 22.04 (Jetson Linux), Wayland 디스플레이 서버

**동기화 메커니즘**: Wayland 프레임 콜백 기반 VSync 동기화, 2프레임 주기 동작 (짝수: 검은 화면 + 촬영, 홀수: 결과 투사)

**AI 추론**: Ultralytics YOLO, TensorRT FP16 최적화 (약 112ms 추론 시간, 초당 8-9회)

**UI 프레임워크**: PySide6 기반 GUI (카메라/비디오 전환, 모델 선택, 실시간 성능 모니터링)

### 성능 지표

60Hz 디스플레이에서 30fps로 안정적으로 동작하며, 프레임 드랍은 거의 발생하지 않습니다. YOLO 추론은 TensorRT FP16 기준 약 112ms로, 초당 8-9회 추론이 가능합니다. 현재 구성에서는 컨베이어 속도가 초당 수십 cm 이하인 환경에 적합하며, 빠른 컨베이어에서는 추론 성능 향상이 필요합니다.

---

## 앞으로 해야 할 작업

### 1단계: 현장 배포 준비 (1-2개월)

#### 하드웨어 케이싱 및 설치

현재 시스템은 개발 보드 상태로 노출되어 있어, 먼지와 습기로부터 보호할 수 있는 산업용 케이스가 필요합니다. 알루미늄 또는 ABS 재질의 케이스를 제작하여 Jetson, 전원, 네트워크 장비를 수납하고, 통풍구를 통해 방열이 가능하도록 설계할 예정입니다. 케이스는 DIN 레일 마운트를 지원하여 설치 현장의 다양한 환경에 대응할 수 있도록 합니다.

카메라와 프로젝터의 정렬도 중요한 과제입니다. 컨베이어 벨트 위 3m x 1m 영역을 정확히 커버하려면, 카메라와 프로젝터의 위치, 각도, 초점을 정밀하게 조정해야 합니다. 조절 가능한 마운트 브래킷을 설계하여 현장에서 미세 조정이 가능하도록 하고, 캘리브레이션 도구를 개발하여 카메라 좌표와 프로젝터 투사 좌표를 매핑할 예정입니다. 이를 통해 AI가 인식한 객체의 정확한 위치에 마킹을 투사할 수 있습니다.

#### 자동 실행 및 복구 시스템

현장 배포 시 재부팅이나 전원 차단 후에도 자동으로 시스템이 실행되어야 합니다. systemd 서비스를 생성하여 부팅 시 자동 실행되도록 설정하고, Wayland 세션이 준비될 때까지 대기하는 로직을 추가할 예정입니다. 또한 프로세스가 비정상 종료되면 자동으로 재시작하는 watchdog를 구현합니다.

카메라나 네트워크 연결이 일시적으로 끊어졌을 때 자동 재연결 메커니즘도 필요합니다. 현재는 연결 실패 시 에러를 발생시키고 종료하지만, 현장에서는 연결이 복구될 때까지 재시도하고, 복구되면 자동으로 작업을 재개해야 합니다. 상태 머신을 구현하여 연결 실패, 복구 시도, 정상 작동 등의 상태를 관리할 예정입니다.

#### 로깅 및 모니터링 시스템

현재는 터미널 출력으로만 로그를 확인할 수 있는데, 현장 배포 후에는 파일 기반 로깅이 필수적입니다. 날짜별로 로그 파일을 분리하고, 문제 발생 시 원인을 추적할 수 있도록 합니다. 로그 파일이 너무 커지지 않도록 로테이션 정책도 적용합니다. 또한 원격 로깅 시스템도 검토 중이며, 중요한 이벤트나 오류 발생 시 중앙 서버로 로그를 전송하여 여러 현장의 상태를 통합 모니터링할 수 있도록 할 예정입니다.

성능 지표(FPS, 추론 시간, 탐지 객체 수, 프레임 드랍 횟수 등)를 시계열 데이터로 저장하여 시스템 성능을 추적할 수 있어야 합니다. 이를 통해 시간대별 성능 변화를 분석하고, 성능 저하가 발생하는 시점을 파악할 수 있습니다. 간단한 웹 대시보드를 구축하여 현장 작업자가 시스템 상태를 실시간으로 확인할 수 있도록 할 예정입니다.

### 2단계: 원격 관리 시스템 구축 (2-3개월)

#### 네트워크 인프라 설계

현장에서 인터넷이나 WiFi를 사용하기 어려운 환경일 수 있습니다. 몇 가지 대안을 검토 중입니다. 첫 번째는 현장에 직접 유선 랜을 끌어와 WiFi 공유기를 설치하는 방법입니다. 이는 가장 안정적이지만 현장 환경에 따라 설치가 어려울 수 있습니다.

두 번째는 LTE/5G 모뎀을 Jetson에 직접 연결하는 방법입니다. 월 데이터 요금이 발생하지만 장소에 구애받지 않고 원격 접속이 가능합니다. 다만 재활용 선별장이 지하나 금속 구조물로 둘러싸인 경우 신호 수신이 어려울 수 있어, 외부 안테나를 연장하는 방안도 고려해야 합니다.

세 번째는 LoRaWAN과 같은 저전력 원거리 통신 기술을 사용하는 방법입니다. 실시간 영상 전송은 불가능하지만, 상태 정보나 로그 데이터를 주기적으로 전송하고 간단한 제어 명령을 받는 정도는 가능합니다. 여러 현장을 운영할 때 게이트웨이 하나로 다수의 장치를 관리할 수 있어 비용 효율적입니다.

#### 원격 배포 및 업데이트

현장에 설치된 시스템의 소프트웨어를 원격으로 업데이트할 수 있어야 유지보수 비용을 줄일 수 있습니다. Docker 컨테이너 기반으로 애플리케이션을 패키징하고, Balena 또는 AWS IoT Greengrass 같은 OTA(Over-The-Air) 업데이트 플랫폼을 활용할 예정입니다. 이를 통해 새로운 AI 모델이나 소프트웨어 패치를 현장 방문 없이 배포할 수 있습니다.

업데이트 중 문제가 발생하면 이전 버전으로 자동 롤백되는 메커니즘도 필요합니다. A/B 파티션 방식을 사용하여 새 버전을 별도 파티션에 설치하고, 부팅 테스트를 통과하면 전환하는 방식으로 안정성을 확보할 예정입니다.

#### 원격 진단 및 문제 해결

문제 발생 시 원격으로 진단하고 해결할 수 있는 도구가 필요합니다. VPN을 통한 SSH 접속을 기본으로 하되, 네트워크 문제로 SSH 접속이 안 될 때를 대비해 대체 수단도 마련해야 합니다. 예를 들어 시리얼 콘솔 접속을 위한 GSM 모뎀이나, 원격 재부팅을 위한 스마트 파워 스위치를 함께 설치하는 방안을 검토 중입니다.

간단한 문제는 작업자가 직접 해결할 수 있도록 진단 스크립트와 매뉴얼을 제공할 예정입니다. 예를 들어 카메라 연결 확인, 네트워크 테스트, 프로젝터 정렬 등을 단계별로 안내하는 CLI 도구를 개발합니다.

### 3단계: AI 모델 성능 향상 (3-6개월)

#### 재활용품 특화 데이터셋 구축

현재는 범용 COCO 데이터셋으로 학습된 YOLO 모델을 사용하고 있지만, 재활용품에 특화된 모델이 필요합니다. 1차적으로 국내 공개 데이터셋을 활용하여 모델을 학습한 후, 현장에서 수집한 데이터로 추가 학습을 진행할 계획입니다.

**공개 데이터셋 활용**: AI Hub에서 제공하는 대규모 재활용품 데이터셋을 활용합니다. 주요 데이터셋으로는 폐플라스틱 이미지 데이터(약 80만 건, 세그멘테이션), 재활용품 분류 및 선별 데이터(100만 건, 바운딩박스+세그멘테이션), 생활폐기물 데이터(약 55만 set, 바운딩박스) 등이 있습니다. 이들 데이터셋은 PE, PET, PP, PS 등 플라스틱 재질별 분류와 캔, 병, 비닐 등 형태별 분류 정보를 포함하고 있어, 실제 선별장 환경과 유사한 학습이 가능합니다.

특히 폐플라스틱 데이터셋은 세그멘테이션(Polygon) 라벨을 제공하여 겹쳐진 물체를 정밀하게 구분할 수 있고, 재활용품 100만 건 데이터셋은 대량 학습에 적합합니다. 클래스 분포가 균일한 산업폐기물 데이터셋(10종, 각 2만 건)도 초기 학습에 활용할 수 있습니다. 국제적으로는 TACO(Trash Annotations in Context) 데이터셋(약 1,500 이미지, 4,784 어노테이션)을 보조 데이터로 사용하여 일반화 성능을 높일 수 있습니다.

**현장 데이터 수집**: 공개 데이터셋으로 기본 모델을 학습한 후, 실제 선별장에서 촬영한 데이터를 추가로 수집합니다. 여러 재활용 선별장에서 다양한 조명, 컨베이어 속도, 물체 배치 상황을 포함하여 정확도를 높입니다. Roboflow나 LabelImg 같은 도구로 라벨링을 진행하고, 데이터 증강(rotation, flip, brightness 조정 등)을 통해 학습 데이터를 확장하며 과적합을 방지합니다. 공개 데이터셋과 현장 데이터를 결합한 Transfer Learning 방식으로 최적의 성능을 달성할 계획입니다.

#### 다양한 모델 실험

YOLO 외에도 RT-DETR, EfficientDet, YOLOX 등 다양한 객체 탐지 모델을 실험할 예정입니다. RT-DETR은 Transformer 기반으로 최근 주목받고 있으며, NMS(Non-Maximum Suppression) 없이도 높은 정확도를 보입니다. Jetson에서의 추론 속도를 테스트하여 YOLO와 비교할 것입니다.

세그멘테이션 모델도 고려하고 있습니다. 바운딩 박스만으로는 겹쳐진 물체를 정확히 구분하기 어려운데, 픽셀 단위 세그멘테이션을 사용하면 각 물체의 정확한 경계를 파악할 수 있습니다. YOLOv8-seg나 Mask R-CNN 같은 모델을 실험하되, 추론 속도가 느려지는 것을 감안해야 합니다.

모델 경량화도 중요한 과제입니다. Knowledge Distillation을 사용하여 큰 모델의 지식을 작은 모델로 전이하거나, Pruning과 Quantization을 통해 모델 크기를 줄이면서도 정확도를 유지할 수 있는지 연구할 예정입니다.

#### 모델 성능 평가 체계

모델의 정확도를 객관적으로 평가하기 위한 테스트 데이터셋과 메트릭이 필요합니다. mAP(mean Average Precision), Precision, Recall, F1 Score 등의 지표를 추적하고, 특히 재활용품 분류에서 중요한 항목(예: 페트병, 캔)의 정확도를 별도로 측정합니다.

현장 테스트도 중요합니다. 실제 선별장에 시제품을 설치하고 일정 기간 동안 작업자의 피드백을 받아, AI가 놓친 물체나 잘못 분류한 경우를 기록합니다. 이 데이터를 다시 학습에 반영하는 Active Learning 방식으로 모델을 지속적으로 개선할 계획입니다.

### 4단계: MLOps 파이프라인 구축 (병행 진행)

#### 개발-테스트-배포 자동화

모델 개발부터 현장 배포까지의 과정을 자동화하는 파이프라인이 필요합니다. 데이터 수집 → 라벨링 → 학습 → 평가 → TensorRT 변환 → 성능 테스트 → 배포의 전 과정을 추적하고 재현 가능하도록 관리해야 합니다.

DVC(Data Version Control)를 사용하여 데이터셋 버전을 관리하고, MLflow나 Weights & Biases로 실험 결과를 추적할 예정입니다. 각 실험의 하이퍼파라미터, 학습 곡선, 최종 성능 지표를 기록하여 어떤 설정이 가장 좋은 결과를 냈는지 비교할 수 있습니다.

CI/CD 파이프라인을 구축하여, 새로운 모델이 일정 성능 기준을 통과하면 자동으로 현장 장비에 배포되도록 할 수 있습니다. 다만 현장 배포 전에 스테이징 환경에서 충분히 테스트하는 단계를 거쳐 안정성을 확보합니다.

#### 학습 인프라 확보

Jetson에서 직접 모델을 학습하기에는 성능이 부족합니다. 클라우드 GPU 인스턴스(AWS, GCP, Azure)를 사용하거나, 온프레미스 워크스테이션에 고성능 GPU를 구축해야 합니다.

예산이 제한적이라면 Google Colab Pro나 Paperspace Gradient 같은 저렴한 클라우드 GPU 서비스를 활용할 수 있습니다. 학습 시간이 길어지면 비용이 증가하므로, 효율적인 학습 전략(Transfer Learning, Mixed Precision Training 등)을 사용하여 비용을 최적화합니다.

장기적으로는 자체 GPU 서버 구축을 고려해야 합니다. RTX 4090 워크스테이션이면 대부분의 실험을 감당할 수 있으며, 클라우드 비용보다 장기적으로 경제적입니다. 서버 관리와 쿨링, 전력 공급 등의 인프라 투자가 필요하지만, 데이터 보안과 실험 유연성 측면에서 장점이 있습니다.

### 5단계: 하드웨어 업그레이드 검토

#### 고성능 컴퓨팅 플랫폼

현재 Orin Nano 8GB는 프로토타입에는 충분하지만, 현장 배포 시 더 높은 성능이 필요할 수 있습니다. 복잡한 모델이나 다중 카메라를 사용하려면 Jetson Orin NX 16GB(157 TOPS) 또는 AGX Orin 64GB(275 TOPS)로 업그레이드를 고려해야 합니다.

AGX Orin은 여러 AI 모델을 동시 실행하거나, 트래킹과 같은 추가 기능을 구현할 때 유리합니다. 또한 64GB 메모리로 대용량 배치 처리가 가능하여, 높은 프레임레이트가 필요한 환경에 적합합니다.

#### 고급 카메라 및 프로젝터

현재 2.3MP 카메라는 기본적인 분류에는 충분하지만, 미세한 특징 구분이나 먼 거리 촬영에는 한계가 있습니다. 5MP 이상의 고해상도 산업용 카메라를 사용하면 더 정확한 인식이 가능합니다. 또한 다중 카메라 구성으로 넓은 영역을 커버하거나 스테레오 비전을 구현할 수도 있습니다.

프로젝터도 업그레이드를 고려할 수 있습니다. Genlock이나 3D Sync를 지원하는 고급 프로젝터를 사용하면 하드웨어 레벨에서 동기화가 가능하여 더 정밀한 타이밍 제어가 가능합니다. 4K 해상도 프로젝터를 사용하면 더 세밀한 마킹이 가능하고, 6000-8000 안시루멘급으로 밝기를 높이면 야외나 밝은 환경에서도 선명한 투사가 가능합니다.

---

## 예산 및 리소스 계획

### 현재 시스템 (저가형 구성)

- Jetson Orin Nano 8GB: 약 30만 원
- GigE 카메라 (2.3MP 글로벌 셔터): 약 20만 원
- 레이저 프로젝터 (FHD 5000안시): 약 140만 원
- 저장장치 및 기타: 약 10만 원
- **총 예상 비용: 약 200만 원**

프로토타입과 소규모 테스트에 적합하며, 전력 소비가 낮고 소형이라 설치가 용이합니다.

### 중가형 구성 (연구개발용)

- Jetson Orin NX 16GB: 약 130만 원
- 산업용 카메라 (2MP, 40fps): 약 80만 원
- 고급 레이저 프로젝터 (렌즈시프트 지원): 약 300만 원
- 저장장치 및 케이스: 약 30만 원
- **총 예상 비용: 약 540만 원**

본격적인 연구개발 및 파일럿 프로젝트에 적합하며, 중간 규모 재활용 센터에서 활용할 수 있습니다.

### GPU 학습 인프라

**클라우드 옵션**:
- AWS/GCP GPU 인스턴스: 시간당 약 $3-4 (월 100시간 사용 시 약 50만 원)
- Google Colab Pro+: 월 약 $50 (6만 원), GPU 시간 제한 있음

**온프레미스 옵션**:
- RTX 4090 워크스테이션: 약 800-1,000만 원
- 장기적으로 클라우드보다 경제적이며, 데이터 보안과 실험 유연성 확보

---

## 기술적 과제 및 리스크

### 현장 환경 적응

재활용 선별장은 먼지, 습기, 진동이 많은 열악한 환경입니다. 전자장비가 장시간 안정적으로 작동하려면 방진/방습 케이스와 충분한 방열이 필수적입니다. 특히 여름철 고온 환경에서 Jetson의 스로틀링이 발생하지 않도록 냉각 시스템을 강화해야 합니다.

컨베이어 벨트의 진동이 카메라와 프로젝터의 정렬을 흐트러뜨릴 수 있습니다. 진동 흡수 마운트를 사용하거나, 주기적으로 캘리브레이션을 수행하여 정렬을 유지해야 합니다. 자동 캘리브레이션 기능을 개발하면 유지보수 부담을 줄일 수 있습니다.

### 조명 조건 변화

재활용 선별장의 조명은 시간대나 날씨에 따라 변할 수 있습니다. 창문으로 들어오는 자연광이나 작업등의 밝기 변화가 카메라 촬영과 AI 인식에 영향을 줄 수 있습니다. 카메라의 자동 노출 기능을 활용하거나, 조명 보정 알고리즘을 적용하여 다양한 조명 조건에서 안정적인 인식 성능을 확보해야 합니다.

프로젝터 투사도 주변 조명의 영향을 받습니다. 밝은 환경에서는 프로젝터의 밝기가 부족해 작업자가 마킹을 보기 어려울 수 있으므로, 충분히 밝은 프로젝터를 선택하거나 주변 조명을 일부 차단하는 방안을 고려해야 합니다.

### 실시간 성능 보장

컨베이어 속도가 빠르면 AI 추론 시간이 병목이 될 수 있습니다. 현재 112ms의 추론 시간으로는 초당 8-9회 추론이 가능한데, 컨베이어가 빠르게 움직이면 물체를 놓칠 수 있습니다. 모델 경량화, 하드웨어 업그레이드, 또는 트래킹 알고리즘을 통해 프레임 간 물체를 추적하는 방식으로 보완할 수 있습니다.

멀티스레딩을 활용하여 카메라 촬영, AI 추론, 프로젝터 렌더링을 병렬 처리하면 전체 지연시간을 줄일 수 있습니다. 현재는 순차적으로 처리하지만, 파이프라인 방식으로 전환하여 각 단계가 동시에 진행되도록 최적화할 예정입니다.

### 데이터 프라이버시 및 보안

현장에서 촬영한 영상 데이터를 클라우드로 전송할 때 개인정보나 기업 기밀이 포함될 수 있습니다. 재활용품 자체는 민감한 정보가 아니지만, 작업자가 함께 촬영되거나 선별장 내부 구조가 노출될 수 있습니다.

엣지 컴퓨팅을 최대한 활용하여 데이터를 로컬에서 처리하고, 꼭 필요한 메타데이터만 전송하는 방식으로 프라이버시를 보호할 수 있습니다. 또한 전송 데이터는 암호화하고, 접근 권한을 엄격히 관리해야 합니다.

---

## 성공 지표

### 기술적 지표

- **인식 정확도**: 재활용품 분류 정확도 95% 이상 (주요 카테고리 기준)
- **추론 속도**: 평균 100ms 이하로 실시간 처리 가능
- **시스템 안정성**: 24시간 연속 가동 시 99% 이상 가동률
- **동기화 정확도**: VSync와 카메라 트리거 오차 ±5ms 이내

### 운영 지표

- **설치 시간**: 현장 설치 및 캘리브레이션 4시간 이내 완료
- **유지보수 주기**: 월 1회 이하의 현장 방문으로 유지 가능
- **원격 업데이트**: 95% 이상의 업데이트를 원격으로 완료
- **고장 복구 시간**: 문제 발생 후 24시간 이내 복구

### 비즈니스 지표

- **작업 효율 개선**: 기존 대비 분류 속도 30% 향상
- **오분류 감소**: 잘못 분류된 재활용품 50% 감소
- **ROI**: 설비 투자 비용 2년 이내 회수
- **현장 만족도**: 작업자 설문 조사 4점 이상 (5점 만점)

---

## 마일스톤

### 1분기 (현재 ~ 3개월)
- 현장 배포용 케이싱 및 마운트 설계 완료
- 자동 실행 및 복구 시스템 구현
- 로깅 및 모니터링 시스템 구축
- 첫 현장 파일럿 테스트 (1개소)

### 2분기 (4-6개월)
- 원격 관리 시스템 구축 (네트워크, OTA 업데이트)
- 재활용품 데이터셋 1차 구축 (5,000장 이상)
- RT-DETR, YOLOv8-seg 등 다양한 모델 실험
- 학습 인프라 확보 (클라우드 또는 온프레미스)

### 3분기 (7-9개월)
- MLOps 파이프라인 구축
- 재활용품 특화 모델 1차 배포
- 추가 현장 테스트 (3-5개소)
- 성능 데이터 수집 및 분석

### 4분기 (10-12개월)
- 하드웨어 업그레이드 검토 및 테스트
- 시스템 안정화 및 최적화
- 대규모 배포 준비 (10개소 이상)
- 사업화 전략 수립

---

## 결론

지금까지 VSync 기반 카메라-프로젝터 동기화라는 핵심 기술을 성공적으로 구현했고, YOLO 기반 실시간 객체 인식 시스템을 구축했습니다. Jetson 플랫폼의 제약을 극복하고, Wayland 환경에서 안정적인 프레임 동기화를 달성했으며, TensorRT 최적화를 통해 실시간 추론 성능을 확보했습니다.

앞으로는 프로토타입을 실제 현장에 배포할 수 있는 수준으로 발전시켜야 합니다. 하드웨어 케이싱과 자동 실행, 원격 관리 시스템을 구축하여 현장 유지보수 부담을 줄이고, 재활용품에 특화된 AI 모델을 개발하여 인식 정확도를 높일 것입니다. MLOps 파이프라인을 구축하여 모델 개선을 지속적으로 진행하고, 필요에 따라 하드웨어를 업그레이드하여 성능을 확장할 수 있습니다.

이 프로젝트는 단순한 기술 데모를 넘어, 실제 재활용 산업에 기여할 수 있는 실용적인 솔루션으로 발전할 것입니다.
