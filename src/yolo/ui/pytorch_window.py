#coding=utf-8
"""
PyTorch ì „ìš© ìœˆë„ìš°
ëª¨ë¸ ì •ë³´ + í´ë˜ìŠ¤ ëª©ë¡ í‘œì‹œ + ì¹´ë©”ë¼/ë¹„ë””ì˜¤ ì œì–´
"""
from pathlib import Path
from PySide6.QtWidgets import (QMainWindow, QLabel, QVBoxLayout, QWidget, 
                                QPushButton, QHBoxLayout, QSizePolicy, QComboBox, 
                                QGroupBox, QRadioButton, QButtonGroup, 
                                QTextEdit, QScrollArea)
from PySide6.QtCore import Qt
from camera.camera_controller import CameraController
from camera.video_file_controller import VideoFileController
from ui.widgets.camera_control_widget import CameraControlWidget
from ui.widgets.video_control_widget import VideoControlWidget
from ui.widgets.inference_config_widget import InferenceConfigWidget
from inference.engine import InferenceEngine
from inference.worker import InferenceWorker
from inference.config import PTConfig


class PyTorchWindow(QMainWindow):
    """PyTorch ì „ìš© ìœˆë„ìš°"""
    
    def __init__(self, model_manager):
        super().__init__()
        
        self.model_manager = model_manager
        self.inference_config = PTConfig()
        self.inference_engine = InferenceEngine(
            model_manager.current_model,
            model_manager.model_list[0][1] if model_manager.model_list else None,
            self.inference_config
        )
        
        self.inference_worker = InferenceWorker(self.inference_engine)
        self.inference_worker.result_ready.connect(self._on_inference_result)
        
        self.source = None
        self.source_type = 'camera'
        self.is_running = False
        self.is_paused = False
        self.video_files = self._scan_video_files()
        self._pixmap_cache = None
        
        self.setWindowTitle("YOLO PyTorch Model")
        self.setGeometry(100, 100, 1400, 720)
        self._init_ui()
        self._update_source_ui()
        self._init_camera_early()
    
    def _init_ui(self):
        """UI ì´ˆê¸°í™”"""
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QHBoxLayout()
        
        # ì™¼ìª½: ë¹„ë””ì˜¤ ë””ìŠ¤í”Œë ˆì´
        video_layout = QVBoxLayout()
        
        self.video_label = QLabel()
        self.video_label.setAlignment(Qt.AlignCenter)
        self.video_label.setStyleSheet("background-color: black;")
        self.video_label.setMinimumSize(640, 480)
        self.video_label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        video_layout.addWidget(self.video_label, stretch=1)
        
        self.status_label = QLabel("ì´ˆê¸°í™” ì¤‘...")
        self.status_label.setAlignment(Qt.AlignCenter)
        video_layout.addWidget(self.status_label)
        
        main_layout.addLayout(video_layout, stretch=3)
        
        # ì˜¤ë¥¸ìª½: ì»¨íŠ¸ë¡¤ íŒ¨ë„
        control_panel = self._create_control_panel()
        main_layout.addWidget(control_panel, stretch=1)
        
        central_widget.setLayout(main_layout)
    
    def _create_control_panel(self):
        """ì»¨íŠ¸ë¡¤ íŒ¨ë„"""
        panel = QWidget()
        panel.setMaximumWidth(350)
        layout = QVBoxLayout()
        
        # ëª¨ë¸ ì •ë³´
        layout.addWidget(self._create_model_info())
        
        # ì†ŒìŠ¤ ì„ íƒ
        layout.addWidget(self._create_source_selector())
        
        # ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ
        self.video_file_group = self._create_video_file_selector()
        layout.addWidget(self.video_file_group)
        
        # ëª¨ë¸ ì„ íƒ
        layout.addWidget(self._create_model_selector())
        
        # ì¶”ë¡  ì„¤ì •
        self.inference_config_widget = InferenceConfigWidget(self.inference_config)
        self.inference_config_widget.config_changed.connect(self._on_inference_config_changed)
        layout.addWidget(self.inference_config_widget)
        
        # ì¹´ë©”ë¼ ì œì–´
        self.camera_widget = CameraControlWidget()
        self.camera_widget.start_camera.connect(self._on_start_camera)
        self.camera_widget.stop_camera.connect(self._on_stop_camera)
        layout.addWidget(self.camera_widget)
        
        # ë¹„ë””ì˜¤ ì œì–´
        self.video_widget = VideoControlWidget(self.video_files)
        self.video_widget.play_pause.connect(self._on_video_play_pause)
        self.video_widget.stop.connect(self._on_video_stop)
        self.video_widget.step_frame.connect(self._on_step_frame)
        self.video_widget.seek_requested.connect(self._on_seek_frame)
        self.video_widget.fps_changed.connect(self._on_fps_changed)
        self.video_widget.loop_changed.connect(self._on_loop_changed)
        layout.addWidget(self.video_widget)
        
        # ì´ˆê¸° ìƒíƒœ ì„¤ì •
        self._update_control_visibility()
        layout.addStretch()
        
        panel.setLayout(layout)
        return panel
    
    def _create_model_info(self):
        """ëª¨ë¸ ì •ë³´ ìœ„ì ¯"""
        group = QGroupBox("PyTorch ëª¨ë¸ ì •ë³´")
        layout = QVBoxLayout()
        
        # ìŠ¤í¬ë¡¤ ì˜ì—­
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setMaximumHeight(300)
        
        info_widget = QWidget()
        info_layout = QVBoxLayout()
        
        self.info_text = QTextEdit()
        self.info_text.setReadOnly(True)
        
        # ëª¨ë¸ ì •ë³´ í‘œì‹œ
        model = self.model_manager.current_model
        model_path = self.model_manager.model_list[0][1]
        
        info_text = self._get_model_info(model, model_path)
        self.info_text.setText(info_text)
        
        info_layout.addWidget(self.info_text)
        info_widget.setLayout(info_layout)
        scroll.setWidget(info_widget)
        
        layout.addWidget(scroll)
        group.setLayout(layout)
        return group
    
    def _get_model_info(self, model, model_path):
        """ëª¨ë¸ ìƒì„¸ ì •ë³´ ìƒì„±"""
        info = []
        
        # ê¸°ë³¸ ì •ë³´
        info.append(f"ğŸ“„ íŒŒì¼: {Path(model_path).name}")
        file_size_mb = Path(model_path).stat().st_size / (1024 * 1024)
        info.append(f"ğŸ’¾ í¬ê¸°: {file_size_mb:.1f} MB")
        
        if hasattr(model, 'task'):
            info.append(f"ğŸ¯ Task: {model.task}")
        
        # íŒŒë¼ë¯¸í„° ìˆ˜
        if hasattr(model, 'model'):
            try:
                total_params = sum(p.numel() for p in model.model.parameters())
                info.append(f"âš™ï¸ íŒŒë¼ë¯¸í„°: {total_params:,}")
            except:
                pass
        
        # í´ë˜ìŠ¤ ëª©ë¡ ì „ì²´ í‘œì‹œ
        if hasattr(model, 'names'):
            info.append(f"\nğŸ“‹ í´ë˜ìŠ¤ ({len(model.names)}ê°œ):")
            for idx, name in model.names.items():
                info.append(f"  {idx}: {name}")
        
        return '\n'.join(info)
    
    def _create_control_buttons(self):
        """ì œì–´ ë²„íŠ¼"""
        group = QGroupBox("ì œì–´")
        layout = QHBoxLayout()
        
        self.start_button = QPushButton("â–¶ ì‹œì‘")
        self.start_button.clicked.connect(self._on_start)
        self.start_button.setMinimumHeight(40)
        layout.addWidget(self.start_button)
        
        self.stop_button = QPushButton("â¸ ì¤‘ì§€")
        self.stop_button.clicked.connect(self._on_stop)
        self.stop_button.setEnabled(False)
        self.stop_button.setMinimumHeight(40)
        layout.addWidget(self.stop_button)
        
        self.quit_button = QPushButton("âœ• ì¢…ë£Œ")
        self.quit_button.clicked.connect(self.close)
        self.quit_button.setMinimumHeight(40)
        layout.addWidget(self.quit_button)
        
        group.setLayout(layout)
        return group
    
    def _create_source_selector(self):
        """ì†ŒìŠ¤ ì„ íƒ"""
        group = QGroupBox("ì…ë ¥ ì†ŒìŠ¤")
        layout = QHBoxLayout()
        
        self.source_button_group = QButtonGroup()
        self.camera_radio = QRadioButton("ì¹´ë©”ë¼")
        self.file_radio = QRadioButton("íŒŒì¼")
        self.camera_radio.setChecked(True)
        
        self.source_button_group.addButton(self.camera_radio)
        self.source_button_group.addButton(self.file_radio)
        self.camera_radio.toggled.connect(self._on_source_changed)
        
        layout.addWidget(self.camera_radio)
        layout.addWidget(self.file_radio)
        group.setLayout(layout)
        return group
    
    def _create_video_file_selector(self):
        """ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ"""
        group = QGroupBox("ë¹„ë””ì˜¤ íŒŒì¼")
        layout = QVBoxLayout()
        
        self.video_combo = QComboBox()
        for video_path in self.video_files:
            video_name = Path(video_path).name
            self.video_combo.addItem(video_name, video_path)
        layout.addWidget(self.video_combo)
        
        group.setLayout(layout)
        return group
    
    def _create_model_selector(self):
        """ëª¨ë¸ ì„ íƒ"""
        group = QGroupBox("ëª¨ë¸ ì„ íƒ")
        layout = QVBoxLayout()
        
        # Task ì„ íƒ (ë¨¼ì € ìƒì„±)
        task_layout = QHBoxLayout()
        task_layout.addWidget(QLabel("Task:"))
        self.task_combo = QComboBox()
        self.task_combo.addItems(['detect', 'segment', 'classify', 'pose', 'obb'])
        self.task_combo.setCurrentText('detect')
        task_layout.addWidget(self.task_combo)
        layout.addLayout(task_layout)
        
        # ëª¨ë¸ ì½¤ë³´ë°•ìŠ¤ (ë‚˜ì¤‘ì— ìƒì„±)
        self.model_combo = QComboBox()
        
        for model_name, model_path in self.model_manager.model_list:
            self.model_combo.addItem(model_name, model_path)
        
        self.model_combo.currentIndexChanged.connect(self._on_model_changed)
        layout.addWidget(self.model_combo)
        
        group.setLayout(layout)
        return group
    
    def _scan_video_files(self):
        """ë¹„ë””ì˜¤ íŒŒì¼ ìŠ¤ìº”"""
        samples_dir = Path(__file__).parent.parent / "samples"
        if not samples_dir.exists():
            return []
        
        extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm']
        video_files = []
        for ext in extensions:
            video_files.extend(samples_dir.glob(f"*{ext}"))
        
        return sorted([str(f) for f in video_files])
    
    def _init_camera_early(self):
        """ì¹´ë©”ë¼ ì‚¬ì „ ì´ˆê¸°í™”"""
        if self.source_type != 'camera':
            return
        
        try:
            self.source = CameraController()
            self.source.initialize()
            self._setup_camera_controls()
            print("âœ… ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.status_label.setText("ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - íŒŒì¼ ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”")
    
    def _setup_camera_controls(self):
        """ì¹´ë©”ë¼ ì»¨íŠ¸ë¡¤ ì´ˆê¸°í™”"""
        if not self.source or self.source_type != 'camera':
            return
        
        try:
            resolutions, current_index = self.source.get_resolutions()
            self.camera_widget.setup_resolution(resolutions, current_index)
            print("âœ… ì¹´ë©”ë¼ ì»¨íŠ¸ë¡¤ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì»¨íŠ¸ë¡¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.status_label.setText(f"ì»¨íŠ¸ë¡¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _on_source_changed(self):
        """ì†ŒìŠ¤ ë³€ê²½"""
        if self.is_running or self.is_paused:
            return
        
        self.source_type = 'camera' if self.camera_radio.isChecked() else 'file'
        self._update_source_ui()
        self._update_control_visibility()
    
    def _update_source_ui(self):
        """ì†ŒìŠ¤ì— ë”°ë¥¸ UI ì—…ë°ì´íŠ¸"""
        is_camera = self.source_type == 'camera'
        self.video_file_group.setVisible(not is_camera)
        
        mode = "ì¹´ë©”ë¼" if is_camera else "ë¹„ë””ì˜¤ íŒŒì¼"
        self.status_label.setText(f"{mode} ëª¨ë“œ")
    
    def _update_control_visibility(self):
        """ì†ŒìŠ¤ì— ë”°ë¥¸ ì»¨íŠ¸ë¡¤ ê°€ì‹œì„±"""
        is_camera = self.source_type == 'camera'
        self.camera_widget.setVisible(is_camera)
        self.video_widget.setVisible(not is_camera)
    
    def _on_model_changed(self, index):
        """ëª¨ë¸ ë³€ê²½"""
        if index < 0 or self.is_running:
            return
        
        model_path = self.model_combo.itemData(index)
        if not model_path:
            return
        
        # ëª¨ë¸ ì „í™˜
        task = self.task_combo.currentText()
        new_model = self.model_manager.switch_model(model_path, task)
        
        # ì¶”ë¡  ì—”ì§„ ì—…ë°ì´íŠ¸
        self.inference_engine.model = new_model
        self.inference_engine.model_path = model_path
        self.inference_engine.is_engine = False
        
        # ì •ë³´ ì—…ë°ì´íŠ¸
        self._update_model_info(new_model, model_path)
        
        print(f"âœ… ëª¨ë¸ ë³€ê²½: {Path(model_path).name}")
    
    def _update_model_info(self, model, model_path):
        """ëª¨ë¸ ì •ë³´ ì—…ë°ì´íŠ¸"""
        info_text = self._get_model_info(model, model_path)
        self.info_text.setText(info_text)
    
    def _on_start_camera(self):
        """ì¹´ë©”ë¼ ì‹œì‘"""
        if not self._init_source():
            self.camera_widget._on_stop()
            return
        
        self.is_running = True
        self.is_paused = False
        self.source.is_running = True
        self.inference_engine.reset_stats()
        self._pixmap_cache = None
        
        if not self.inference_worker.isRunning():
            self.inference_worker.start()
        
        self.source.start_trigger()
        self.status_label.setText("ì‹¤í–‰ ì¤‘...")
        print("\nğŸ¬ ì¹´ë©”ë¼ ì‹œì‘")
    
    def _on_stop_camera(self):
        """ì¹´ë©”ë¼ ì¤‘ì§€"""
        self._on_stop()
    
    def _on_video_play_pause(self):
        """ë¹„ë””ì˜¤ ì¬ìƒ/ì¼ì‹œì •ì§€"""
        if self.is_paused:
            self._on_resume()
        elif self.is_running:
            self._on_pause()
        else:
            self._on_start()
    
    def _on_video_stop(self):
        """ë¹„ë””ì˜¤ ì¤‘ì§€"""
        self._on_stop()
    
    def _on_step_frame(self, delta):
        """í”„ë ˆì„ ë‹¨ìœ„ ì´ë™ (ì¼ì‹œì •ì§€ ì¤‘ì—ë§Œ)"""
        if not self.is_paused or not self.source or self.source_type != 'file':
            return
        
        frame = self.source.step_frame(delta)
        if frame is not None:
            self._process_single_frame(frame)
    
    def _on_seek_frame(self, frame_number):
        """íŠ¹ì • í”„ë ˆì„ìœ¼ë¡œ ì´ë™"""
        if not self.source or self.source_type != 'file':
            return
        
        # ì¬ìƒ ì¤‘ì´ë©´ ì¼ì‹œì ìœ¼ë¡œ ë©ˆì¶”ê³  íƒìƒ‰
        was_running = self.is_running
        if was_running:
            self.source.stop_trigger()
        
        self.source.seek_frame(frame_number)
        
        # ì¼ì‹œì •ì§€ ì¤‘ì´ë©´ í”„ë ˆì„ í‘œì‹œ
        if self.is_paused:
            frame = self.source.step_frame(0)
            if frame is not None:
                self._process_single_frame(frame)
        
        # ì¬ìƒ ì¤‘ì´ì—ˆìœ¼ë©´ ë‹¤ì‹œ ì‹œì‘
        if was_running:
            target_fps = self.video_widget.fps_slider.value()
            self.source.start_trigger(target_fps)
    
    def _on_loop_changed(self, loop):
        """ë£¨í”„ ì„¤ì • ë³€ê²½"""
        if self.source and self.source_type == 'file':
            self.source.loop = loop
            print(f"âœ… ë£¨í”„ ì¬ìƒ: {loop}")
    
    def _on_progress_updated(self, current_frame, total_frames, time_sec):
        """ì§„í–‰ë¥  ì—…ë°ì´íŠ¸"""
        self.video_widget.update_progress(current_frame, total_frames, time_sec)
    
    def _reprocess_current_frame(self):
        """í˜„ì¬ í”„ë ˆì„ ì¬ì¶”ë¡  (ì¼ì‹œì •ì§€ ì¤‘)"""
        if not self.source or self.source_type != 'file':
            return
        
        frame = self.source.get_current_frame()
        if frame is not None:
            self._process_single_frame(frame)
    
    def _process_single_frame(self, frame):
        """ë‹¨ì¼ í”„ë ˆì„ ì¶”ë¡  (ì¼ì‹œì •ì§€ìš©)"""
        q_image, stats = self.inference_engine.process_frame(frame)
        self._display_frame(q_image)
        self._update_status_label(stats)
    
    def _on_fps_changed(self, fps):
        """FPS ë³€ê²½"""
        if not self.source or not self.is_running or self.source_type != 'file':
            return
        
        self.source.target_fps = fps
        if hasattr(self.source, '_update_timer_interval'):
            self.source._update_timer_interval()
    
    def _on_inference_config_changed(self, config):
        """ì¶”ë¡  ì„¤ì • ë³€ê²½ (ì¬ìƒ/ì¼ì‹œì •ì§€ ì¤‘ ëª¨ë‘ ì ìš©)"""
        self.inference_config = config
        self.inference_engine.config = config
        print(f"âœ… ì¶”ë¡  ì„¤ì •: conf={config.conf:.2f}, iou={config.iou:.2f}, "
              f"imgsz={config.imgsz}, max_det={config.max_det}, augment={config.augment}")
        
        # ì¼ì‹œì •ì§€ ì¤‘ì´ë©´ í˜„ì¬ í”„ë ˆì„ ì¬ì¶”ë¡  (ì¬ìƒ ì¤‘ì—ëŠ” ìë™ ì ìš©)
        if hasattr(self, 'is_paused') and self.is_paused and self.source and self.source_type == 'file':
            if hasattr(self, '_reprocess_current_frame'):
                self._reprocess_current_frame()
    
    def _on_frame_ready(self, frame_bgr):
        """í”„ë ˆì„ ì½œë°±"""
        if not self.is_running or self.inference_worker.processing:
            return
        
        self.inference_worker.submit_frame(frame_bgr)
    
    def _on_inference_result(self, q_image, stats):
        """ì¶”ë¡  ê²°ê³¼ ì½œë°±"""
        if not self.is_running:
            return
        
        self._display_frame(q_image)
        self._update_status_label(stats)
    
    def _display_frame(self, q_image):
        """í”„ë ˆì„ ë””ìŠ¤í”Œë ˆì´"""
        label_size = self.video_label.size()
        scaled_pixmap, cache_key = InferenceEngine.scale_pixmap(
            q_image, label_size, self._pixmap_cache
        )
        self._pixmap_cache = (cache_key, scaled_pixmap)
        self.video_label.setPixmap(scaled_pixmap)
    
    def _update_status_label(self, stats):
        """ìƒíƒœ ë¼ë²¨ ì—…ë°ì´íŠ¸"""
        text = (f"FPS: {stats['fps']:.1f} | "
                f"ì¶”ë¡ : {stats['infer_time']:.1f}ms "
                f"(í‰ê· : {stats['avg_infer_time']:.1f}ms) | "
                f"íƒì§€: {stats['detected_count']} | "
                f"í•´ìƒë„: {stats['frame_width']}x{stats['frame_height']}")
        self.status_label.setText(text)
    
    def _on_start(self):
        """ë¹„ë””ì˜¤ ì‹œì‘"""
        if not self._init_source():
            return
        
        self.is_running = True
        self.is_paused = False
        self.source.is_running = True
        self.inference_engine.reset_stats()
        self._pixmap_cache = None
        
        if not self.inference_worker.isRunning():
            self.inference_worker.start()
        
        target_fps = self.video_widget.fps_slider.value()
        self.source.start_trigger(target_fps)
        
        self.video_widget.set_playing(True)
        self.video_widget.set_controls_enabled(False)
        self.status_label.setText("ì‹¤í–‰ ì¤‘...")
        print(f"\nğŸ¬ ë¹„ë””ì˜¤ ì‹œì‘ (FPS: {target_fps})")
    
    def _on_pause(self):
        """ì¼ì‹œì •ì§€ (ë¹„ë””ì˜¤ë§Œ)"""
        if not self.is_running:
            return
        
        self.is_paused = True
        self.is_running = False
        self.source.is_running = False
        self.source.stop_trigger()
        
        self.video_widget.set_playing(False)
        self.video_widget.set_controls_enabled(True)
        self.status_label.setText("ì¼ì‹œì •ì§€")
        print("â¸ ì¼ì‹œì •ì§€")
    
    def _on_resume(self):
        """ì¬ê°œ (ì¼ì‹œì •ì§€ í•´ì œ)"""
        if not self.is_paused:
            return
        
        self.is_paused = False
        self.is_running = True
        self.source.is_running = True
        
        target_fps = self.video_widget.fps_slider.value()
        self.source.start_trigger(target_fps)
        
        self.video_widget.set_playing(True)
        self.video_widget.set_controls_enabled(False)
        self.status_label.setText("ì‹¤í–‰ ì¤‘...")
        print("â–¶ ì¬ê°œ")
    
    def _init_source(self):
        """ì†ŒìŠ¤ ì´ˆê¸°í™”"""
        try:
            if self.source_type == 'camera':
                if self.source and isinstance(self.source, CameraController):
                    self.source.signals.frame_ready.connect(self._on_frame_ready)
                else:
                    self.source = CameraController()
                    self.source.initialize()
                    self.source.signals.frame_ready.connect(self._on_frame_ready)
                    self._setup_camera_controls()
            else:
                video_path = self.video_combo.currentData()
                if not video_path:
                    self.status_label.setText("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”")
                    return False
                
                self.source = VideoFileController(video_path)
                self.source.initialize()
                self.source.signals.frame_ready.connect(self._on_frame_ready)
                self.source.signals.progress_updated.connect(self._on_progress_updated)
                # ë¹„ë””ì˜¤ ì •ë³´ ì „ë‹¬
                self.video_widget.set_video_info(self.source.total_frames, self.source.video_fps)
            
            return True
        except Exception as e:
            print(f"âŒ ì†ŒìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.status_label.setText(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _on_stop(self):
        """ì¤‘ì§€ (ì™„ì „ ì •ì§€, ì†ŒìŠ¤ í•´ì œ)"""
        if not self.source:
            return
        
        self.is_running = False
        self.is_paused = False
        self.source.is_running = False
        
        try:
            self.source.signals.frame_ready.disconnect(self._on_frame_ready)
        except:
            pass
        
        try:
            if self.source_type == 'file':
                self.source.signals.progress_updated.disconnect(self._on_progress_updated)
        except:
            pass
        
        self.source.stop_trigger()
        
        if self.source_type == 'camera':
            # ì¹´ë©”ë¼ëŠ” cleanupí•˜ì§€ ì•ŠìŒ
            pass
        else:
            self.source.cleanup()
            self.source = None
            self.video_widget.set_playing(False)
            self.video_widget.set_controls_enabled(False)
        
        self.video_label.clear()
        self.status_label.setText("ì¤‘ì§€ë¨")
        print("â¹ ì¤‘ì§€")
    
    
    def resizeEvent(self, event):
        """ìœˆë„ìš° í¬ê¸° ë³€ê²½"""
        super().resizeEvent(event)
        self._pixmap_cache = None
    
    def closeEvent(self, event):
        """ìœˆë„ìš° ì¢…ë£Œ"""
        if self.is_running:
            self._on_stop()
        
        if self.inference_worker.isRunning():
            self.inference_worker.stop()
        
        if self.source:
            self.source.cleanup()
        
        event.accept()

