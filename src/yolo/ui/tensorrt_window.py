#coding=utf-8
"""
TensorRT ì „ìš© ìœˆë„ìš°
ì—”ì§„ ì •ë³´ í‘œì‹œ + ì¹´ë©”ë¼/ë¹„ë””ì˜¤ ì œì–´
"""
from pathlib import Path
from PySide6.QtWidgets import (QMainWindow, QLabel, QVBoxLayout, QWidget, 
                                QPushButton, QHBoxLayout, QSizePolicy, QComboBox, 
                                QGroupBox, QRadioButton, QButtonGroup, QStackedWidget, 
                                QTextEdit, QScrollArea)
from PySide6.QtCore import Qt
from camera.camera_controller import CameraController
from camera.video_file_controller import VideoFileController
from ui.widgets.camera_control_widget import CameraControlWidget
from ui.widgets.video_control_widget import VideoControlWidget
from ui.widgets.inference_config_widget import InferenceConfigWidget
from inference.engine import InferenceEngine
from inference.worker import InferenceWorker
from inference.config import EngineConfig


class TensorRTWindow(QMainWindow):
    """TensorRT ì „ìš© ìœˆë„ìš°"""
    
    def __init__(self, model_manager):
        super().__init__()
        
        self.model_manager = model_manager
        self.inference_config = EngineConfig()
        self.inference_engine = InferenceEngine(
            model_manager.current_model,
            model_manager.model_list[0][1] if model_manager.model_list else None,
            self.inference_config
        )
        
        self.inference_worker = InferenceWorker(self.inference_engine)
        self.inference_worker.result_ready.connect(self._on_inference_result)
        
        self.source = None
        self.source_type = 'camera'
        self.is_running = False
        self.video_files = self._scan_video_files()
        self._pixmap_cache = None
        
        self.setWindowTitle("YOLO TensorRT Engine")
        self.setGeometry(100, 100, 1400, 720)
        self._init_ui()
        self._update_source_ui()
        self._init_camera_early()
    
    def _init_ui(self):
        """UI ì´ˆê¸°í™”"""
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        main_layout = QHBoxLayout()
        
        # ì™¼ìª½: ë¹„ë””ì˜¤ ë””ìŠ¤í”Œë ˆì´
        video_layout = QVBoxLayout()
        
        self.video_label = QLabel()
        self.video_label.setAlignment(Qt.AlignCenter)
        self.video_label.setStyleSheet("background-color: black;")
        self.video_label.setMinimumSize(640, 480)
        self.video_label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        video_layout.addWidget(self.video_label, stretch=1)
        
        self.status_label = QLabel("ì´ˆê¸°í™” ì¤‘...")
        self.status_label.setAlignment(Qt.AlignCenter)
        video_layout.addWidget(self.status_label)
        
        main_layout.addLayout(video_layout, stretch=3)
        
        # ì˜¤ë¥¸ìª½: ì»¨íŠ¸ë¡¤ íŒ¨ë„
        control_panel = self._create_control_panel()
        main_layout.addWidget(control_panel, stretch=1)
        
        central_widget.setLayout(main_layout)
    
    def _create_control_panel(self):
        """ì»¨íŠ¸ë¡¤ íŒ¨ë„"""
        panel = QWidget()
        panel.setMaximumWidth(350)
        layout = QVBoxLayout()
        
        # ì—”ì§„ ì •ë³´
        layout.addWidget(self._create_engine_info())
        
        # ì œì–´ ë²„íŠ¼
        layout.addWidget(self._create_control_buttons())
        
        # ì†ŒìŠ¤ ì„ íƒ
        layout.addWidget(self._create_source_selector())
        
        # ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ
        self.video_file_group = self._create_video_file_selector()
        layout.addWidget(self.video_file_group)
        
        # ëª¨ë¸ ì„ íƒ
        layout.addWidget(self._create_model_selector())
        
        # ì¶”ë¡  ì„¤ì •
        self.inference_config_widget = InferenceConfigWidget(self.inference_config)
        self.inference_config_widget.config_changed.connect(self._on_inference_config_changed)
        layout.addWidget(self.inference_config_widget)
        
        # ì¹´ë©”ë¼/ë¹„ë””ì˜¤ ì„¤ì •
        self.control_stack = QStackedWidget()
        self.camera_widget = CameraControlWidget()
        self.camera_widget.resolution_changed.connect(self._on_resolution_changed)
        self.control_stack.addWidget(self.camera_widget)
        
        self.video_widget = VideoControlWidget(self.video_files)
        self.video_widget.fps_changed.connect(self._on_fps_changed)
        self.control_stack.addWidget(self.video_widget)
        
        layout.addWidget(self.control_stack)
        layout.addStretch()
        
        panel.setLayout(layout)
        return panel
    
    def _create_engine_info(self):
        """ì—”ì§„ ì •ë³´ ìœ„ì ¯"""
        group = QGroupBox("TensorRT ì—”ì§„ ì •ë³´")
        layout = QVBoxLayout()
        
        # ìŠ¤í¬ë¡¤ ì˜ì—­
        scroll = QScrollArea()
        scroll.setWidgetResizable(True)
        scroll.setMaximumHeight(300)
        
        info_widget = QWidget()
        info_layout = QVBoxLayout()
        
        self.info_text = QTextEdit()
        self.info_text.setReadOnly(True)
        
        # ì—”ì§„ ì •ë³´ í‘œì‹œ
        model = self.model_manager.current_model
        model_path = self.model_manager.model_list[0][1]
        
        info_text = self._get_engine_info(model, model_path)
        self.info_text.setText(info_text)
        
        info_layout.addWidget(self.info_text)
        info_widget.setLayout(info_layout)
        scroll.setWidget(info_widget)
        
        layout.addWidget(scroll)
        group.setLayout(layout)
        return group
    
    def _get_engine_info(self, model, model_path):
        """ì—”ì§„ ìƒì„¸ ì •ë³´ ìƒì„±"""
        info = []
        
        # ê¸°ë³¸ ì •ë³´
        info.append(f"ğŸ“„ íŒŒì¼: {Path(model_path).name}")
        file_size_mb = Path(model_path).stat().st_size / (1024 * 1024)
        info.append(f"ğŸ’¾ í¬ê¸°: {file_size_mb:.1f} MB")
        
        if hasattr(model, 'task'):
            info.append(f"ğŸ¯ Task: {model.task}")
        
        # í´ë˜ìŠ¤ ì •ë³´
        if hasattr(model, 'names'):
            info.append(f"\nğŸ“‹ í´ë˜ìŠ¤ ({len(model.names)}ê°œ):")
            for idx, name in model.names.items():
                info.append(f"  {idx}: {name}")
        
        # ì—”ì§„ ì„¸ë¶€ ì •ë³´
        info.append(f"\nâš™ï¸ ì—”ì§„ êµ¬ì¡°:")
        
        # Taskë³„ ì¶œë ¥ í˜•ì‹
        task = model.task if hasattr(model, 'task') else 'detect'
        
        if task == 'detect':
            info.append(f"  ì¶œë ¥ í˜•ì‹:")
            info.append(f"    â€¢ num_dets: íƒì§€ëœ ê°ì²´ ìˆ˜")
            info.append(f"    â€¢ det_boxes: [N, 4] ë°•ìŠ¤ ì¢Œí‘œ")
            info.append(f"    â€¢ det_scores: [N] ì‹ ë¢°ë„")
            info.append(f"    â€¢ det_classes: [N] í´ë˜ìŠ¤ ID")
            info.append(f"    (ë˜ëŠ” [N, 4+nc] ì›ì‹œ ì˜ˆì¸¡)")
        elif task == 'segment':
            info.append(f"  ì¶œë ¥ í˜•ì‹:")
            info.append(f"    â€¢ íƒì§€ ì¶œë ¥ (ìœ„ì™€ ë™ì¼)")
            info.append(f"    â€¢ proto: ë§ˆìŠ¤í¬ ì›í˜•")
            info.append(f"    â€¢ mask_coeff: ë§ˆìŠ¤í¬ ê³„ìˆ˜")
        elif task == 'pose':
            info.append(f"  ì¶œë ¥ í˜•ì‹:")
            info.append(f"    â€¢ ë°•ìŠ¤/í´ë˜ìŠ¤/ìŠ¤ì½”ì–´")
            info.append(f"    â€¢ keypoints: [N, K*2 or K*3]")
        elif task == 'classify':
            info.append(f"  ì¶œë ¥ í˜•ì‹:")
            info.append(f"    â€¢ [N, num_classes] ë¡œì§“ í…ì„œ")
        
        # NMS í”ŒëŸ¬ê·¸ì¸ ê°ì§€
        try:
            model_name = Path(model_path).name.lower()
            if 'e2e' in model_name or 'end2end' in model_name:
                info.append(f"\n  ğŸ”Œ NMS í”ŒëŸ¬ê·¸ì¸: EfficientNMS_TRT (E2E)")
            else:
                info.append(f"\n  ğŸ”Œ NMS: í‘œì¤€ í›„ì²˜ë¦¬")
        except:
            pass
        
        return '\n'.join(info)
    
    def _create_control_buttons(self):
        """ì œì–´ ë²„íŠ¼"""
        group = QGroupBox("ì œì–´")
        layout = QHBoxLayout()
        
        self.start_button = QPushButton("â–¶ ì‹œì‘")
        self.start_button.clicked.connect(self._on_start)
        self.start_button.setMinimumHeight(40)
        layout.addWidget(self.start_button)
        
        self.stop_button = QPushButton("â¸ ì¤‘ì§€")
        self.stop_button.clicked.connect(self._on_stop)
        self.stop_button.setEnabled(False)
        self.stop_button.setMinimumHeight(40)
        layout.addWidget(self.stop_button)
        
        self.quit_button = QPushButton("âœ• ì¢…ë£Œ")
        self.quit_button.clicked.connect(self.close)
        self.quit_button.setMinimumHeight(40)
        layout.addWidget(self.quit_button)
        
        group.setLayout(layout)
        return group
    
    def _create_source_selector(self):
        """ì†ŒìŠ¤ ì„ íƒ"""
        group = QGroupBox("ì…ë ¥ ì†ŒìŠ¤")
        layout = QHBoxLayout()
        
        self.source_button_group = QButtonGroup()
        self.camera_radio = QRadioButton("ì¹´ë©”ë¼")
        self.file_radio = QRadioButton("íŒŒì¼")
        self.camera_radio.setChecked(True)
        
        self.source_button_group.addButton(self.camera_radio)
        self.source_button_group.addButton(self.file_radio)
        self.camera_radio.toggled.connect(self._on_source_changed)
        
        layout.addWidget(self.camera_radio)
        layout.addWidget(self.file_radio)
        group.setLayout(layout)
        return group
    
    def _create_video_file_selector(self):
        """ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ"""
        group = QGroupBox("ë¹„ë””ì˜¤ íŒŒì¼")
        layout = QVBoxLayout()
        
        self.video_combo = QComboBox()
        for video_path in self.video_files:
            video_name = Path(video_path).name
            self.video_combo.addItem(video_name, video_path)
        layout.addWidget(self.video_combo)
        
        group.setLayout(layout)
        return group
    
    def _create_model_selector(self):
        """ëª¨ë¸ ì„ íƒ"""
        group = QGroupBox("ì—”ì§„ ì„ íƒ")
        layout = QVBoxLayout()
        
        self.model_combo = QComboBox()
        
        for model_name, model_path in self.model_manager.model_list:
            self.model_combo.addItem(model_name, model_path)
        
        self.model_combo.currentIndexChanged.connect(self._on_model_changed)
        layout.addWidget(self.model_combo)
        
        group.setLayout(layout)
        return group
    
    def _scan_video_files(self):
        """ë¹„ë””ì˜¤ íŒŒì¼ ìŠ¤ìº”"""
        samples_dir = Path(__file__).parent.parent / "samples"
        if not samples_dir.exists():
            return []
        
        extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm']
        video_files = []
        for ext in extensions:
            video_files.extend(samples_dir.glob(f"*{ext}"))
        
        return sorted([str(f) for f in video_files])
    
    def _init_camera_early(self):
        """ì¹´ë©”ë¼ ì‚¬ì „ ì´ˆê¸°í™”"""
        if self.source_type != 'camera':
            return
        
        try:
            self.source = CameraController()
            self.source.initialize()
            self._setup_camera_controls()
            print("âœ… ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.status_label.setText("ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - íŒŒì¼ ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”")
    
    def _setup_camera_controls(self):
        """ì¹´ë©”ë¼ ì»¨íŠ¸ë¡¤ ì´ˆê¸°í™”"""
        if not self.source or self.source_type != 'camera':
            return
        
        try:
            resolutions, current_index = self.source.get_resolutions()
            self.camera_widget.setup_resolution(resolutions, current_index)
            print("âœ… ì¹´ë©”ë¼ ì»¨íŠ¸ë¡¤ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì»¨íŠ¸ë¡¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.status_label.setText(f"ì»¨íŠ¸ë¡¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def _on_source_changed(self):
        """ì†ŒìŠ¤ ë³€ê²½"""
        if self.is_running:
            return
        
        self.source_type = 'camera' if self.camera_radio.isChecked() else 'file'
        self._update_source_ui()
    
    def _update_source_ui(self):
        """ì†ŒìŠ¤ì— ë”°ë¥¸ UI ì—…ë°ì´íŠ¸"""
        is_camera = self.source_type == 'camera'
        self.video_file_group.setVisible(not is_camera)
        self.control_stack.setCurrentIndex(0 if is_camera else 1)
        
        mode = "ì¹´ë©”ë¼" if is_camera else "ë¹„ë””ì˜¤ íŒŒì¼"
        self.status_label.setText(f"{mode} ëª¨ë“œ - ì‹œì‘ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")
    
    def _on_model_changed(self, index):
        """ëª¨ë¸ ë³€ê²½"""
        if index < 0 or self.is_running:
            return
        
        model_path = self.model_combo.itemData(index)
        if not model_path:
            return
        
        # ëª¨ë¸ ì „í™˜
        new_model = self.model_manager.switch_model(model_path, task='detect')
        
        # ì¶”ë¡  ì—”ì§„ ì—…ë°ì´íŠ¸
        self.inference_engine.model = new_model
        self.inference_engine.model_path = model_path
        self.inference_engine.is_engine = True
        
        # ì •ë³´ ì—…ë°ì´íŠ¸
        self._update_engine_info(new_model, model_path)
        
        print(f"âœ… ì—”ì§„ ë³€ê²½: {Path(model_path).name}")
    
    def _update_engine_info(self, model, model_path):
        """ì—”ì§„ ì •ë³´ ì—…ë°ì´íŠ¸"""
        info_text = self._get_engine_info(model, model_path)
        self.info_text.setText(info_text)
    
    def _on_resolution_changed(self, resolution):
        """í•´ìƒë„ ë³€ê²½"""
        if self.is_running or not self.source:
            return
        self.source.set_resolution(resolution)
    
    def _on_fps_changed(self, fps):
        """FPS ë³€ê²½"""
        if not self.source or not self.is_running or self.source_type != 'file':
            return
        
        self.source.target_fps = fps
        if hasattr(self.source, '_update_timer_interval'):
            self.source._update_timer_interval()
    
    def _on_inference_config_changed(self, config):
        """ì¶”ë¡  ì„¤ì • ë³€ê²½"""
        self.inference_config = config
        self.inference_engine.config = config
        print(f"âœ… ì—”ì§„ ì„¤ì •: conf={config.conf:.2f}, iou={config.iou:.2f}, "
              f"max_det={config.max_det}, agnostic_nms={config.agnostic_nms}")
    
    def _on_frame_ready(self, frame_bgr):
        """í”„ë ˆì„ ì½œë°±"""
        if not self.is_running or self.inference_worker.processing:
            return
        
        self.inference_worker.submit_frame(frame_bgr)
    
    def _on_inference_result(self, q_image, stats):
        """ì¶”ë¡  ê²°ê³¼ ì½œë°±"""
        if not self.is_running:
            return
        
        self._display_frame(q_image)
        self._update_status_label(stats)
    
    def _display_frame(self, q_image):
        """í”„ë ˆì„ ë””ìŠ¤í”Œë ˆì´"""
        label_size = self.video_label.size()
        scaled_pixmap, cache_key = InferenceEngine.scale_pixmap(
            q_image, label_size, self._pixmap_cache
        )
        self._pixmap_cache = (cache_key, scaled_pixmap)
        self.video_label.setPixmap(scaled_pixmap)
    
    def _update_status_label(self, stats):
        """ìƒíƒœ ë¼ë²¨ ì—…ë°ì´íŠ¸"""
        text = (f"FPS: {stats['fps']:.1f} | "
                f"ì¶”ë¡ : {stats['infer_time']:.1f}ms "
                f"(í‰ê· : {stats['avg_infer_time']:.1f}ms) | "
                f"íƒì§€: {stats['detected_count']} | "
                f"í•´ìƒë„: {stats['frame_width']}x{stats['frame_height']}")
        self.status_label.setText(text)
    
    def _on_start(self):
        """ì‹œì‘"""
        if not self._init_source():
            return
        
        self.is_running = True
        self.source.is_running = True
        self.inference_engine.reset_stats()
        self._pixmap_cache = None
        
        if not self.inference_worker.isRunning():
            self.inference_worker.start()
        
        if self.source_type == 'camera':
            self.source.start_trigger()
            print("\nğŸ¬ ì¹´ë©”ë¼ ì‹œì‘")
        else:
            target_fps = self.video_widget.fps_slider.value()
            self.source.start_trigger(target_fps)
            print(f"\nğŸ¬ ë¹„ë””ì˜¤ ì‹œì‘ (FPS: {target_fps})")
        
        self._set_ui_running(True)
        self.status_label.setText("ì‹¤í–‰ ì¤‘...")
    
    def _init_source(self):
        """ì†ŒìŠ¤ ì´ˆê¸°í™”"""
        try:
            if self.source_type == 'camera':
                if self.source and isinstance(self.source, CameraController):
                    self.source.signals.frame_ready.connect(self._on_frame_ready)
                else:
                    self.source = CameraController()
                    self.source.initialize()
                    self.source.signals.frame_ready.connect(self._on_frame_ready)
                    self._setup_camera_controls()
            else:
                video_path = self.video_combo.currentData()
                if not video_path:
                    self.status_label.setText("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”")
                    return False
                
                self.source = VideoFileController(video_path)
                self.source.initialize()
                self.source.signals.frame_ready.connect(self._on_frame_ready)
            
            return True
        except Exception as e:
            print(f"âŒ ì†ŒìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.status_label.setText(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _on_stop(self):
        """ì¤‘ì§€"""
        if not self.source:
            return
        
        self.is_running = False
        self.source.is_running = False
        
        try:
            self.source.signals.frame_ready.disconnect(self._on_frame_ready)
        except:
            pass
        
        self.source.stop_trigger()
        
        if self.source_type == 'file':
            self.source.cleanup()
            self.source = None
        
        self._set_ui_running(False)
        self.status_label.setText("ì¤‘ì§€ë¨")
    
    def _set_ui_running(self, running):
        """UI ì‹¤í–‰ ìƒíƒœ ì„¤ì •"""
        self.start_button.setEnabled(not running)
        self.stop_button.setEnabled(running)
        self.model_combo.setEnabled(not running)
        self.camera_radio.setEnabled(not running)
        self.file_radio.setEnabled(not running)
    
    def resizeEvent(self, event):
        """ìœˆë„ìš° í¬ê¸° ë³€ê²½"""
        super().resizeEvent(event)
        self._pixmap_cache = None
    
    def closeEvent(self, event):
        """ìœˆë„ìš° ì¢…ë£Œ"""
        if self.is_running:
            self._on_stop()
        
        if self.inference_worker.isRunning():
            self.inference_worker.stop()
        
        if self.source:
            self.source.cleanup()
        
        event.accept()

