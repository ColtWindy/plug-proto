#coding=utf-8
"""
YOLO ì¹´ë©”ë¼ ë©”ì¸ ìœˆë„ìš°
UI ë ˆì´ì•„ì›ƒ, ë””ìŠ¤í”Œë ˆì´
"""
import time
from pathlib import Path
import cv2
from ultralytics import YOLO
from PySide6.QtWidgets import (QMainWindow, QLabel, QVBoxLayout, QWidget, 
                                QPushButton, QHBoxLayout, QSizePolicy, QComboBox, 
                                QGroupBox, QRadioButton, QButtonGroup, QStackedWidget)
from PySide6.QtCore import Qt
from PySide6.QtGui import QImage, QPixmap
from camera.camera_controller import CameraController
from camera.video_file_controller import VideoFileController
from ui.widgets.camera_control_widget import CameraControlWidget
from ui.widgets.video_control_widget import VideoControlWidget


class YOLOCameraWindow(QMainWindow):
    """YOLO ì¹´ë©”ë¼ ìœˆë„ìš°"""
    
    def __init__(self, model, model_list):
        super().__init__()
        self.model = model
        self.model_list = model_list
        self.camera = None
        self.source_type = 'camera'
        
        self.setWindowTitle("YOLO Inference")
        self.setGeometry(100, 100, 1280, 720)
        
        # ìƒíƒœ
        self.is_running = False
        self.frame_width = 0
        self.frame_height = 0
        
        # FPS ê³„ì‚°
        self.fps_start_time = time.time()
        self.fps_frame_count = 0
        self.current_fps = 0.0
        
        # ì¶”ë¡  í†µê³„
        self.last_infer_time = 0.0
        self.infer_times = []
        self.avg_infer_time = 0.0
        
        # ìŠ¤ì¼€ì¼ ìºì‹œ
        self._scaled_cache = None
        self._cache_key = None
        
        # ë¹„ë””ì˜¤ íŒŒì¼ ëª©ë¡
        self.video_files = self._scan_video_files()
        
        # YOLOE í”„ë¡¬í”„íŠ¸ ì„¤ì • (.pt íŒŒì¼ë§Œ)
        if model_list and self._is_yoloe_model(model_list[0][1]) and self._is_pt_file(model_list[0][1]):
            self._setup_yoloe(["car"])
        
        # UI ì´ˆê¸°í™”
        self.init_ui()
        self.init_model_combo()
        self.update_source_ui()
        
        # ì¹´ë©”ë¼ ì‚¬ì „ ì´ˆê¸°í™”
        self.init_camera_early()
    
    def init_ui(self):
        """UI ì´ˆê¸°í™”"""
        central_widget = QWidget()
        self.setCentralWidget(central_widget)
        
        main_layout = QHBoxLayout()
        
        # ì™¼ìª½: ë¹„ë””ì˜¤
        video_layout = QVBoxLayout()
        
        self.video_label = QLabel()
        self.video_label.setAlignment(Qt.AlignCenter)
        self.video_label.setStyleSheet("background-color: black;")
        self.video_label.setMinimumSize(640, 480)
        self.video_label.setSizePolicy(QSizePolicy.Expanding, QSizePolicy.Expanding)
        video_layout.addWidget(self.video_label, stretch=1)
        
        self.status_label = QLabel("ì´ˆê¸°í™” ì¤‘...")
        self.status_label.setAlignment(Qt.AlignCenter)
        video_layout.addWidget(self.status_label)
        
        main_layout.addLayout(video_layout, stretch=3)
        
        # ì˜¤ë¥¸ìª½: ì»¨íŠ¸ë¡¤
        control_panel = self._create_control_panel()
        main_layout.addWidget(control_panel, stretch=1)
        
        central_widget.setLayout(main_layout)
    
    def _create_control_panel(self):
        """ì»¨íŠ¸ë¡¤ íŒ¨ë„ ìƒì„±"""
        panel = QWidget()
        panel.setMaximumWidth(320)
        layout = QVBoxLayout()
        layout.setSpacing(10)
        
        # ì œì–´ ë²„íŠ¼ (ìƒë‹¨)
        button_group = self._create_button_group()
        layout.addWidget(button_group)
        
        # ì†ŒìŠ¤ ì„ íƒ
        source_group = self._create_source_group()
        layout.addWidget(source_group)
        
        # ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ (íŒŒì¼ ëª¨ë“œì¼ ë•Œë§Œ í‘œì‹œ)
        self.video_file_group = self._create_video_file_group()
        layout.addWidget(self.video_file_group)
        
        # ëª¨ë¸ ì„ íƒ
        model_group = self._create_model_group()
        layout.addWidget(model_group)
        
        # ì¹´ë©”ë¼/ë¹„ë””ì˜¤ ì„¤ì • ìœ„ì ¯ (ë™ì  êµì²´)
        self.control_stack = QStackedWidget()
        
        # ì¹´ë©”ë¼ ìœ„ì ¯
        self.camera_widget = CameraControlWidget()
        self.camera_widget.resolution_changed.connect(self.on_resolution_changed)
        self.camera_widget.fps_changed.connect(self.on_fps_changed)
        self.camera_widget.exposure_changed.connect(self.on_exposure_changed)
        self.camera_widget.gain_changed.connect(self.on_gain_changed)
        self.control_stack.addWidget(self.camera_widget)
        
        # ë¹„ë””ì˜¤ ìœ„ì ¯ (ì¬ìƒ ì†ë„ë§Œ)
        self.video_widget = VideoControlWidget(self.video_files)
        self.video_widget.fps_changed.connect(self.on_fps_changed)
        self.control_stack.addWidget(self.video_widget)
        
        layout.addWidget(self.control_stack)
        layout.addStretch()
        
        panel.setLayout(layout)
        return panel
    
    def _create_button_group(self):
        """ì œì–´ ë²„íŠ¼ ê·¸ë£¹"""
        group = QGroupBox("ì œì–´")
        layout = QHBoxLayout()
        
        self.start_button = QPushButton("â–¶ ì‹œì‘")
        self.start_button.clicked.connect(self.start_capture)
        self.start_button.setMinimumHeight(40)
        layout.addWidget(self.start_button)
        
        self.stop_button = QPushButton("â¸ ì¤‘ì§€")
        self.stop_button.clicked.connect(self.stop_capture)
        self.stop_button.setEnabled(False)
        self.stop_button.setMinimumHeight(40)
        layout.addWidget(self.stop_button)
        
        self.quit_button = QPushButton("âœ• ì¢…ë£Œ")
        self.quit_button.clicked.connect(self.close)
        self.quit_button.setMinimumHeight(40)
        layout.addWidget(self.quit_button)
        
        group.setLayout(layout)
        return group
    
    def _create_source_group(self):
        """ì†ŒìŠ¤ ì„ íƒ ê·¸ë£¹"""
        group = QGroupBox("ì…ë ¥ ì†ŒìŠ¤")
        layout = QHBoxLayout()
        
        self.source_button_group = QButtonGroup()
        self.camera_radio = QRadioButton("ì¹´ë©”ë¼")
        self.file_radio = QRadioButton("íŒŒì¼")
        self.camera_radio.setChecked(True)
        
        self.source_button_group.addButton(self.camera_radio)
        self.source_button_group.addButton(self.file_radio)
        self.camera_radio.toggled.connect(self.on_source_changed)
        
        layout.addWidget(self.camera_radio)
        layout.addWidget(self.file_radio)
        
        group.setLayout(layout)
        return group
    
    def _create_video_file_group(self):
        """ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ ê·¸ë£¹"""
        group = QGroupBox("ë¹„ë””ì˜¤ íŒŒì¼")
        layout = QVBoxLayout()
        
        self.video_combo = QComboBox()
        for video_path in self.video_files:
            video_name = Path(video_path).name
            self.video_combo.addItem(video_name, video_path)
        layout.addWidget(self.video_combo)
        
        group.setLayout(layout)
        return group
    
    def _create_model_group(self):
        """ëª¨ë¸ ì„ íƒ ê·¸ë£¹"""
        group = QGroupBox("YOLO ëª¨ë¸")
        layout = QVBoxLayout()
        
        self.model_combo = QComboBox()
        self.model_combo.currentIndexChanged.connect(self.on_model_changed)
        layout.addWidget(self.model_combo)
        
        # Task ì„ íƒ
        task_layout = QHBoxLayout()
        task_layout.addWidget(QLabel("Task:"))
        self.task_combo = QComboBox()
        self.task_combo.addItems(['detect', 'segment', 'classify', 'pose', 'obb'])
        self.task_combo.setCurrentText('detect')
        task_layout.addWidget(self.task_combo)
        layout.addLayout(task_layout)
        
        group.setLayout(layout)
        return group
    
    def _scan_video_files(self):
        """ë¹„ë””ì˜¤ íŒŒì¼ ìŠ¤ìº”"""
        samples_dir = Path(__file__).parent.parent / "samples"
        if not samples_dir.exists():
            return []
        
        video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm']
        video_files = []
        for ext in video_extensions:
            video_files.extend(samples_dir.glob(f"*{ext}"))
        
        return sorted([str(f) for f in video_files])
    
    def _detect_task_from_name(self, model_path):
        """íŒŒì¼ëª…ì—ì„œ task ì¶”ë¡ """
        name = Path(model_path).stem.lower()
        
        if 'seg' in name or 'segment' in name:
            return 'segment'
        elif 'cls' in name or 'classify' in name:
            return 'classify'
        elif 'pose' in name:
            return 'pose'
        elif 'obb' in name:
            return 'obb'
        
        return 'detect'  # ê¸°ë³¸ê°’
    
    def _is_yoloe_model(self, model_path):
        """YOLOE ëª¨ë¸ ê°ì§€"""
        return "yoloe" in Path(model_path).stem.lower()
    
    def _is_pt_file(self, model_path):
        """PyTorch ëª¨ë¸ íŒŒì¼ì¸ì§€ í™•ì¸"""
        return Path(model_path).suffix.lower() == '.pt'
    
    def _setup_yoloe(self, classes):
        """YOLOE í”„ë¡¬í”„íŠ¸ ì„¤ì •"""
        try:
            # YOLO ê°ì²´ íƒ€ì… í™•ì¸
            if not hasattr(self.model, 'set_classes'):
                print(f"âš ï¸ ëª¨ë¸ì— set_classes ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤ (íƒ€ì…: {type(self.model)})")
                return
            
            if not hasattr(self.model, 'get_text_pe'):
                print(f"âš ï¸ ëª¨ë¸ì— get_text_pe ë©”ì„œë“œê°€ ì—†ìŠµë‹ˆë‹¤ - YOLOE ëª¨ë¸ì´ ì•„ë‹ ìˆ˜ ìˆìŠµë‹ˆë‹¤")
                return
                
            text_embeddings = self.model.get_text_pe(classes)
            self.model.set_classes(classes, text_embeddings)
            print(f"âœ… YOLOE í”„ë¡¬í”„íŠ¸: {', '.join(classes)}")
        except Exception as e:
            print(f"âš ï¸ YOLOE í”„ë¡¬í”„íŠ¸ ì„¤ì • ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
    
    def init_model_combo(self):
        """ëª¨ë¸ ì½¤ë³´ë°•ìŠ¤ ì´ˆê¸°í™”"""
        for model_name, model_path in self.model_list:
            self.model_combo.addItem(model_name, model_path)
    
    def on_source_changed(self):
        """ì†ŒìŠ¤ ë³€ê²½"""
        if self.is_running:
            return
        
        self.source_type = 'camera' if self.camera_radio.isChecked() else 'file'
        self.update_source_ui()
    
    def update_source_ui(self):
        """ì†ŒìŠ¤ì— ë”°ë¥¸ UI ì—…ë°ì´íŠ¸"""
        is_camera = self.source_type == 'camera'
        
        # ë¹„ë””ì˜¤ íŒŒì¼ ì„ íƒ í‘œì‹œ/ìˆ¨ê¹€
        self.video_file_group.setVisible(not is_camera)
        
        # ìœ„ì ¯ ì „í™˜ (0: ì¹´ë©”ë¼, 1: ë¹„ë””ì˜¤)
        self.control_stack.setCurrentIndex(0 if is_camera else 1)
        
        # ìƒíƒœ ë©”ì‹œì§€
        if is_camera:
            self.status_label.setText("ì¹´ë©”ë¼ ëª¨ë“œ - ì‹œì‘ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")
        else:
            self.status_label.setText("ë¹„ë””ì˜¤ íŒŒì¼ ëª¨ë“œ - ì‹œì‘ ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")
    
    def init_camera_early(self):
        """ì¹´ë©”ë¼ ì‚¬ì „ ì´ˆê¸°í™” (ì•± ì‹œì‘ ì‹œ 1íšŒë§Œ)"""
        if self.source_type != 'camera':
            return
        
        try:
            self.camera = CameraController()
            self.camera.initialize()
            self.init_camera_controls()
            print("âœ… ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ì¹´ë©”ë¼ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.status_label.setText(f"ì¹´ë©”ë¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - íŒŒì¼ ëª¨ë“œë¥¼ ì‚¬ìš©í•˜ì„¸ìš”")
    
    def init_camera_controls(self):
        """ì¹´ë©”ë¼ ì»¨íŠ¸ë¡¤ ì´ˆê¸°í™”"""
        if not self.camera or self.source_type != 'camera':
            return
        
        try:
            # í•´ìƒë„
            resolutions, current_index = self.camera.get_resolutions()
            self.camera_widget.setup_resolution(resolutions, current_index)
            
            # ë…¸ì¶œ ì‹œê°„
            target_fps = 30
            max_exposure_ms = int(1000 / target_fps * 0.8)
            current_exposure = max_exposure_ms // 2
            self.camera_widget.setup_exposure(1, max_exposure_ms, current_exposure)
            
            # ìˆ˜ë™ ë…¸ì¶œ ì„¤ì •
            self.camera.set_manual_exposure(current_exposure)
            print(f"âœ… ìˆ˜ë™ ë…¸ì¶œ: {current_exposure}ms")
            
            # ê²Œì¸
            gain_min, gain_max = self.camera.get_gain_range()
            current_gain = self.camera.get_current_gain()
            self.camera_widget.setup_gain(gain_min, gain_max, current_gain)
            
        except Exception as e:
            print(f"âŒ ì»¨íŠ¸ë¡¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.status_label.setText(f"ì»¨íŠ¸ë¡¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    
    def on_model_changed(self, index):
        """ëª¨ë¸ ë³€ê²½"""
        if index < 0 or self.is_running:
            return
        
        model_path = self.model_combo.itemData(index)
        if model_path:
            # YOLOE ëª¨ë¸ ì²˜ë¦¬
            if self._is_yoloe_model(model_path):
                self.model = YOLO(model_path)  # task ìë™ ê°ì§€
                
                # .pt íŒŒì¼ë§Œ í”„ë¡¬í”„íŠ¸ ì§€ì›
                if self._is_pt_file(model_path):
                    self._setup_yoloe(["car"])
                    print(f"âœ… ëª¨ë¸ ë³€ê²½: {Path(model_path).name} (YOLOE + prompt)")
                else:
                    print(f"âœ… ëª¨ë¸ ë³€ê²½: {Path(model_path).name} (YOLOE prompt-free)")
                    print("â„¹ï¸ TensorRT ì—”ì§„ì€ prompt-free ëª¨ë“œë¡œ ì‘ë™í•©ë‹ˆë‹¤")
            else:
                # ì¼ë°˜ YOLO ëª¨ë¸
                detected_task = self._detect_task_from_name(model_path)
                self.task_combo.setCurrentText(detected_task)
                
                task = self.task_combo.currentText()
                self.model = YOLO(model_path, task=task)
                print(f"âœ… ëª¨ë¸ ë³€ê²½: {Path(model_path).name} (task={task})")
    
    def on_resolution_changed(self, resolution):
        """í•´ìƒë„ ë³€ê²½"""
        if self.is_running or not self.camera:
            return
        
        self.camera.set_resolution(resolution)
        self.frame_width = 0
        self.frame_height = 0
    
    def on_fps_changed(self, fps):
        """FPS ë³€ê²½"""
        # ì‹¤í–‰ ì¤‘ì´ë©´ íƒ€ê²Ÿ FPS ì—…ë°ì´íŠ¸
        if self.camera and self.is_running:
            self.camera.target_fps = fps
            # ë¹„ë””ì˜¤ ëª¨ë“œë©´ íƒ€ì´ë¨¸ ê°„ê²©ë„ ì—…ë°ì´íŠ¸
            if self.source_type == 'file' and hasattr(self.camera, '_update_timer_interval'):
                self.camera._update_timer_interval()
            print(f"ğŸ”„ FPS ë³€ê²½: {fps}")
        
        # ì¹´ë©”ë¼ ëª¨ë“œì¼ ë•Œë§Œ ìµœëŒ€ ë…¸ì¶œ ì‹œê°„ ì—…ë°ì´íŠ¸
        if self.source_type == 'camera':
            self.camera_widget.update_max_exposure(fps)
    
    def on_exposure_changed(self, value_ms):
        """ë…¸ì¶œ ì‹œê°„ ë³€ê²½"""
        if self.camera:
            self.camera.set_exposure(value_ms)
    
    def on_gain_changed(self, value):
        """ê²Œì¸ ë³€ê²½"""
        if self.camera:
            self.camera.set_gain(value)
    
    def on_camera_frame(self, frame_bgr):
        """ì¹´ë©”ë¼ í”„ë ˆì„ ì½œë°± + ì¶”ë¡  + ë””ìŠ¤í”Œë ˆì´"""
        if not self.is_running:
            return
        
        # í”„ë ˆì„ í¬ê¸°
        if self.frame_width == 0 or self.frame_height == 0:
            self.frame_height, self.frame_width = frame_bgr.shape[:2]
        
        # FPS ê³„ì‚°
        self.fps_frame_count += 1
        elapsed_time = time.time() - self.fps_start_time
        if elapsed_time >= 1.0:
            self.current_fps = self.fps_frame_count / elapsed_time
            self.fps_start_time = time.time()
            self.fps_frame_count = 0
        
        # YOLO ì¶”ë¡ 
        start_time = time.time()
        results = self.model(frame_bgr, verbose=False)
        infer_time = (time.time() - start_time) * 1000
        
        # ê²°ê³¼ ë Œë”ë§
        annotated_frame = results[0].plot()
        detected_count = len(results[0].boxes)
        
        self.last_infer_time = infer_time
        
        # í‰ê·  ì¶”ë¡  ì‹œê°„
        self.infer_times.append(infer_time)
        if len(self.infer_times) > 30:
            self.infer_times.pop(0)
        self.avg_infer_time = sum(self.infer_times) / len(self.infer_times)
        
        # BGR â†’ RGB
        annotated_frame_rgb = cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB)
        
        # QImage ë³€í™˜
        height, width, channel = annotated_frame_rgb.shape
        bytes_per_line = 3 * width
        q_image = QImage(annotated_frame_rgb.data, width, height, 
                        bytes_per_line, QImage.Format_RGB888).copy()
        
        # QPixmap ìŠ¤ì¼€ì¼ë§ (ìºì‹œ ì‚¬ìš©)
        pixmap = QPixmap.fromImage(q_image)
        label_size = self.video_label.size()
        cache_key = (label_size.width(), label_size.height(), pixmap.cacheKey())
        
        if cache_key != self._cache_key:
            self._scaled_cache = pixmap.scaled(label_size, Qt.KeepAspectRatio, 
                                              Qt.FastTransformation)
            self._cache_key = cache_key
        
        self.video_label.setPixmap(self._scaled_cache)
        
        # ìƒíƒœ í‘œì‹œ
        status_text = (f"FPS: {self.current_fps:.1f} | "
                      f"ì¶”ë¡ : {self.last_infer_time:.1f}ms "
                      f"(í‰ê· : {self.avg_infer_time:.1f}ms) | "
                      f"íƒì§€: {detected_count}")
        
        if self.frame_width > 0 and self.frame_height > 0:
            status_text += f" | í•´ìƒë„: {self.frame_width}x{self.frame_height}"
        
        self.status_label.setText(status_text)
    
    def start_capture(self):
        """ìº¡ì²˜ ì‹œì‘"""
        # ì†ŒìŠ¤ ì´ˆê¸°í™”
        if not self._init_source():
            return
        
        # ìƒíƒœ ì´ˆê¸°í™”
        self.is_running = True
        self.camera.is_running = True
        self.fps_start_time = time.time()
        self.fps_frame_count = 0
        self._scaled_cache = None
        self.frame_width = 0
        self.frame_height = 0
        self.infer_times = []
        self.avg_infer_time = 0.0
        
        # ì¹´ë©”ë¼/ë¹„ë””ì˜¤ ì‹œì‘
        if self.source_type == 'camera':
            target_fps = self.camera_widget.fps_slider.value()
        else:
            target_fps = self.video_widget.fps_slider.value()
        
        self.camera.start_trigger(target_fps)
        
        # UI ìƒíƒœ
        self.start_button.setEnabled(False)
        self.stop_button.setEnabled(True)
        self.model_combo.setEnabled(False)
        self.camera_radio.setEnabled(False)
        self.file_radio.setEnabled(False)
        
        status = "ì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ì¤‘..." if self.source_type == 'camera' else "ë¹„ë””ì˜¤ ë¶„ì„ ì¤‘..."
        self.status_label.setText(status)
        
        print(f"\nğŸ¬ ì‹œì‘ (íƒ€ê²Ÿ FPS: {target_fps})")
    
    def _init_source(self):
        """ì†ŒìŠ¤ ì´ˆê¸°í™” (ì¹´ë©”ë¼ ë˜ëŠ” ë¹„ë””ì˜¤)"""
        try:
            if self.source_type == 'camera':
                # ì´ë¯¸ ì´ˆê¸°í™”ëœ ì¹´ë©”ë¼ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
                if self.camera and isinstance(self.camera, CameraController):
                    self.camera.signals.frame_ready.connect(self.on_camera_frame)
                    print("âœ… ê¸°ì¡´ ì¹´ë©”ë¼ ì‚¬ìš©")
                else:
                    self.camera = CameraController()
                    self.camera.initialize()
                    self.camera.signals.frame_ready.connect(self.on_camera_frame)
                    self.init_camera_controls()
                    print("âœ… ì¹´ë©”ë¼ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                video_path = self.video_combo.currentData()
                if not video_path:
                    self.status_label.setText("ë¹„ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”")
                    return False
                
                self.camera = VideoFileController(video_path)
                self.camera.initialize()
                self.camera.signals.frame_ready.connect(self.on_camera_frame)
                
                print(f"âœ… ë¹„ë””ì˜¤ ì´ˆê¸°í™” ì™„ë£Œ: {Path(video_path).name}")
            
            return True
            
        except Exception as e:
            source_name = "ì¹´ë©”ë¼" if self.source_type == 'camera' else "ë¹„ë””ì˜¤"
            print(f"âŒ {source_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.status_label.setText(f"{source_name} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def stop_capture(self):
        """ìº¡ì²˜ ì¤‘ì§€"""
        if not self.camera:
            return
        
        # 1. í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ì§€
        self.is_running = False
        self.camera.is_running = False
        
        # 2. ì‹œê·¸ë„ ì—°ê²° í•´ì œ (ì¤‘ìš”!)
        try:
            self.camera.signals.frame_ready.disconnect(self.on_camera_frame)
        except:
            pass
        
        # 3. íŠ¸ë¦¬ê±° ì¤‘ì§€
        self.camera.stop_trigger()
        
        # 4. ë¹„ë””ì˜¤ ëª¨ë“œë§Œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ (ì¹´ë©”ë¼ëŠ” ìœ ì§€)
        if self.source_type == 'file':
            self.camera.cleanup()
            self.camera = None
        
        # 5. UI ìƒíƒœ
        self.start_button.setEnabled(True)
        self.stop_button.setEnabled(False)
        self.model_combo.setEnabled(True)
        self.camera_radio.setEnabled(True)
        self.file_radio.setEnabled(True)
        self.status_label.setText("ì¤‘ì§€ë¨")
        
        print("âœ… ì¤‘ì§€ ì™„ë£Œ")
    
    def resizeEvent(self, event):
        """ìœˆë„ìš° í¬ê¸° ë³€ê²½"""
        super().resizeEvent(event)
        self._scaled_cache = None
        self._cache_key = None
    
    def closeEvent(self, event):
        """ìœˆë„ìš° ì¢…ë£Œ"""
        if self.is_running:
            self.stop_capture()
        
        if self.camera:
            self.camera.cleanup()
        
        event.accept()

